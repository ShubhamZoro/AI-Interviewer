# ğŸ¤– AI Interviewer

An AI-powered mock interview platform â€” the AI speaks questions aloud, monitors your camera for eye contact, listens to your answers via voice, and delivers a rich feedback report at the end.

## âœ¨ Features

| Feature | Details |
|---------|---------|
| ğŸ™ï¸ **Voice Recording** | Press mic, speak your answer, press stop |
| ğŸ”Š **Streaming AI Voice** | TTS starts playing sentence-by-sentence as text streams in (no waiting for full response) |
| ğŸ“· **Camera Gaze Monitor** | Live webcam with TF.js / MediaPipe face detection â€” flags if you look away |
| ğŸ’¬ **Chat Transcript** | Real-time streaming chat with blinking cursor while AI types |
| ğŸ™‹ **Always Intro First** | Every interview opens with "Tell me about yourself" |
| ğŸ“„ **Resume Upload** | Upload PDF or .txt â€” AI tailors questions to your experience |
| ğŸ“‹ **Job Description** | Paste the JD â€” AI aligns questions to the role requirements |
| ğŸ”¢ **Custom Question Count** | Slider (1â€“15) to choose how many questions you want |
| ğŸ¯ **3 Interview Types** | Technical, Behavioral, Mixed |
| ğŸ“Š **Detailed Feedback** | Score (1â€“100), grade, strengths, improvements + per-question accordion |
| ğŸ‘¤ **Your Full Answer** | Each question shows exactly what you said |
| ğŸ“ **Model Answer** | GPT writes a complete example answer you can learn from |
| ğŸ‘ï¸ **Look-Away Counter** | Tracks how many times you were flagged during the session |

## ğŸ§° Tech Stack

| Layer | Technology |
|-------|-----------|
| Frontend | React + Vite |
| Backend | FastAPI (Python) |
| STT | OpenAI Whisper-1 |
| TTS | OpenAI TTS-1 (`nova` voice) â€” streamed inline in SSE |
| AI (Questions) | GPT-4o-mini (fast streaming) |
| AI (Feedback) | GPT-4o (deep evaluation) |
| Face Detection | TensorFlow.js + MediaPipe Face Detection |
| Design | Vanilla CSS (dark glassmorphism) |

## ğŸ“ Project Structure

```
AI_Interviewer/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py              # FastAPI v3 â€” streaming SSE + concurrent TTS + resume parsing
â”‚   â”œâ”€â”€ requirements.txt     # Python deps (includes pypdf)
â”‚   â””â”€â”€ .env                 # OPENAI_API_KEY (create this)
â””â”€â”€ frontend/
    â”œâ”€â”€ src/
    â”‚   â”œâ”€â”€ pages/
    â”‚   â”‚   â”œâ”€â”€ SetupPage.jsx      # Role, experience, type, question count, resume/JD
    â”‚   â”‚   â”œâ”€â”€ InterviewPage.jsx  # Recording, streaming, camera monitor
    â”‚   â”‚   â””â”€â”€ FeedbackPage.jsx   # Accordion breakdown with answer + model answer
    â”‚   â”œâ”€â”€ components/
    â”‚   â”‚   â”œâ”€â”€ CameraMonitor.jsx  # Webcam + TF.js gaze detection
    â”‚   â”‚   â”œâ”€â”€ WaveformVisualizer.jsx
    â”‚   â”‚   â””â”€â”€ MessageBubble.jsx
    â”‚   â”œâ”€â”€ App.jsx
    â”‚   â”œâ”€â”€ main.jsx
    â”‚   â””â”€â”€ index.css
    â””â”€â”€ .env                 # VITE_API_URL
```

## ğŸš€ Quick Start

### 1. Backend

```bash
cd backend

# Copy env file and add your key
cp .env.example .env
# Edit .env â†’ set OPENAI_API_KEY=sk-...

# Create virtual env and install deps
python -m venv venv
venv\Scripts\activate        # Windows
# source venv/bin/activate  # macOS/Linux

pip install -r requirements.txt
uvicorn main:app --reload --port 8000
```

Backend: http://localhost:8000 Â· Swagger: http://localhost:8000/docs

### 2. Frontend

```bash
cd frontend
npm install
npm run dev
```

Frontend: http://localhost:5173

> **Browser permissions:** Allow **microphone** and **camera** when prompted. Camera is used for gaze monitoring only â€” no video is sent to the server.

## ğŸ”Œ API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| POST | `/api/start-interview` | Start session (FormData: role, experience, type, num_questions, resume?, job_description?) |
| POST | `/api/transcribe` | Audio blob â†’ transcript via Whisper |
| POST | `/api/respond-stream` | Answer â†’ streaming SSE with text tokens + inline base64 TTS audio |
| GET | `/api/tts/{session_id}/{index}` | Cached TTS for the first question |
| POST | `/api/end-interview` | Generate GPT-4o feedback JSON with scores + model answers |
| DELETE | `/api/session/{session_id}` | Clean up session |

## âš™ï¸ Environment Variables

### Backend (`backend/.env`)
```
OPENAI_API_KEY=your-openai-api-key
```

### Frontend (`frontend/.env`)
```
VITE_API_URL=http://localhost:8000
```

## ğŸ—ï¸ How It Works

```
Setup Page
  â”‚  role + experience + interview type + question count
  â”‚  optional: resume (PDF/txt) + job description
  â–¼
POST /api/start-interview  â†’  GPT-4o-mini generates intro question
                           â†’  TTS pre-generated and cached
  â–¼
Interview Loop
  â”‚  User clicks ğŸ™ï¸ â†’ MediaRecorder captures audio
  â”‚  POST /api/transcribe â†’ Whisper â†’ transcript
  â”‚  POST /api/respond-stream (SSE)
  â”‚    â”œâ”€â”€ {type:"text"} events â†’ live streaming bubble
  â”‚    â”œâ”€â”€ asyncio.create_task(_fetch_tts(sentence)) â†’ runs concurrently
  â”‚    â””â”€â”€ {type:"audio"} events â†’ base64 MP3 played inline (no extra fetch!)
  â”‚  Camera: TF.js checks gaze every 1.5s â†’ warns if face not detected
  â–¼
POST /api/end-interview â†’ GPT-4o evaluates full transcript
  â–¼
Feedback Page (accordion per question)
  â”œâ”€â”€ ğŸ‘¤ Your Answer (full, untruncated)
  â”œâ”€â”€ ğŸ’¬ Feedback (specific to what you said)
  â””â”€â”€ ğŸ“ Model Answer (complete example with concrete details)
```
